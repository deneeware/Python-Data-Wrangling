{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f5c6ed",
   "metadata": {},
   "source": [
    "\"We need you to use a collection of questions and answers from the television show 'Jeopardy!' to build a classifier that might work. It is a long-shot, since there isn't a lot of linguistic difference between low- and high-value questions, but even if you can demonstrate it can't be done effectively using some common approaches, it will at least give us something to go on.\"\n",
    "\n",
    "**Basics**\n",
    "\n",
    "Parse, clean, and organize the Jeopardy! question data file to train a Naive Bayesian classifier.\n",
    "\n",
    "Your aim here is to make sense of the data presented, and create a binary classifier (\"high value\" and \"low value,\" based on the points available for each) for questions. Despite the large number of questions, this is an extraordinarily difficult classification problem. \n",
    "\n",
    "Consider it as a human coder: how often could you tell those questions that are \"easy\" versus \"hard\"? The degree to which you are successful in this is largely based on your own contextual knowledge--indeed, you might be tempted to classify questions you know the answer to as \"easy\" and those you do not as \"hard.\" The computer doesn't know the answers to any of these.\n",
    "\n",
    "For that reason, do not be discouraged if your classifier does not perform well. This constitutes an especially difficult problem for a simple classifier to solve.\n",
    "\n",
    "Put the script and its output (which may merely report the accuracy of the trial) in your github repository, and share the link/filenames when you start your quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26f96f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\denee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\denee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\denee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from string import punctuation\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1cbdc",
   "metadata": {},
   "source": [
    "Next, import the 'Jeopardy!' JSON file and view the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc243b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'HISTORY', 'air_date': '2004-12-31', 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\", 'value': '$200', 'answer': 'Copernicus', 'round': 'Jeopardy!', 'show_number': '4680'}\n"
     ]
    }
   ],
   "source": [
    "#import the jeopardy JSON file\n",
    "file_path = 'jeopardy.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    jeopardy_questions = json.load(file)\n",
    "\n",
    "#print the first row if it is in dictionary format\n",
    "print(jeopardy_questions[0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001212c7",
   "metadata": {},
   "source": [
    "Now, clean and organize the questions into \"high\" or \"low\" values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0952f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is a function that converts the 'value' string into an integer by removing the dollar signs\n",
    "\n",
    "#I ran into a lot of errors here and had to go back and forth, not all 'values' were integers nor strings, so I attempted to handle both\n",
    "\n",
    "def clean_value(value):\n",
    "    \"\"\"Ensure the value is returned as an integer.\"\"\"\n",
    "    # Handle cases where the value is None\n",
    "    if value is None:\n",
    "        return 0\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            value = int(value.replace('$', '').replace(',', ''))# Attempt to clean and convert string values\n",
    "        except ValueError:# Return 0 if the string cannot be converted\n",
    "            value = 0\n",
    "    elif not isinstance(value, int):# Return 0 if the value is neither a string nor an integer\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98401cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next function determines if the questions is of 'high' or 'low' value asdetermined by a particular threshold:\n",
    "\n",
    "def determine_value(question, threshold=800):\n",
    "    \"\"\"Determine if the question is of high or low value based on the threshold.\"\"\"\n",
    "    if question['value'] > threshold:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'low'\n",
    "    \n",
    "# Clean the 'value' field and add a 'value_label' field for each question\n",
    "for question in jeopardy_questions:\n",
    "    question['value'] = clean_value(question['value'])\n",
    "    question['value_label'] = determine_value(question)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbbb80",
   "metadata": {},
   "source": [
    "Next, I work on pre-processing the text data(questions) to make them suitable for training a Naive Bayes classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07fe28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize, remove stopwords, and lemmatize text.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()# Convert to lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)# Remove non-alphabetical characters\n",
    "    tokens = word_tokenize(text)# Tokenize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stopwords.words('english')] # Remove stopwords and lemmatize\n",
    "    return cleaned_tokens\n",
    "\n",
    "# Pre-process the question text\n",
    "for question in jeopardy_questions:\n",
    "    question['cleaned_question'] = preprocess_text(question['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8744a77",
   "metadata": {},
   "source": [
    "Next, I work on feature extraction.\n",
    "\n",
    "For Naive Bayes, I convert the questions into a format that the algorithm can process - specifically, a *'bag-of-words'* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef14f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cleaned questions into a list for CountVectorizer\n",
    "cleaned_questions = [\" \".join(question['cleaned_question']) for question in jeopardy_questions]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(cleaned_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d95b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the next code chunk is to prepare the target variable - indicating whether or not each question is \"high\" or 'low' value\n",
    "y = [question['value_label'] for question in jeopardy_questions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9348be9",
   "metadata": {},
   "source": [
    "Finally, the following code works to split the data into training and testing sets to train the Naive Bayes classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2f7c483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6935416954778039\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306713f",
   "metadata": {},
   "source": [
    "An accuracy of approximately 69.35% indicates that our classifier here correctly predicts whether a 'Jeopardy!' question is of \"high\" or \"low\" value around 69.35% of the time based on the question's content. \n",
    "\n",
    "This isn't bad! But could be better, we could explore additional features and try more complex models (that I have yet to learn) to improve the model's predictive accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
