{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2c88d2d",
   "metadata": {},
   "source": [
    "**Essentials**\n",
    "\n",
    "Extend the above classification attempt and try two other approaches to classifying the text.\n",
    "\n",
    "Expand and refine the approach above by providing at least two other approaches to classifying the output.\n",
    "\n",
    "These might also engage in different ways of preparing the materials as well.\n",
    "\n",
    "Given the semantic value of these short texts, using word embeddings might lead to more effective vectorization.\n",
    "\n",
    "You might try: \n",
    "\n",
    "--Support Vector Machines \n",
    "\n",
    "--More Deep Learning approaches by following a Tensor Flow tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4947e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/93/21/9b035a4f823d6aee2917c75415be9a95861ff3d73a0a65e48edbf210cec1/tensorflow-2.15.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.15.0 from https://files.pythonhosted.org/packages/4c/48/1a5a15517f18eaa4ff8d598b1c000300b20c1bb0e624539d702117a0c369/tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.5/57.5 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.2.0 from https://files.pythonhosted.org/packages/08/89/c727fde1a3d12586e0b8c01abf53754707d76beaa9987640e70807d4545f/ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/c1/00/c3ae19cabb36cfabc94ff0b102aac21b471c9f91a1357f8aafffb9efe8e0/protobuf-4.25.2-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.25.2-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.2/1.5 MB 7.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 0.9/1.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 11.8 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/7b/3e/a22e7a0ec6be5454dc540063ac5d0843eb72a4641a0892b54b16b1438c0a/grpcio-1.60.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.60.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.16,>=2.15 from https://files.pythonhosted.org/packages/37/12/f6e9b9dcc310263cbd3948274e286538bd6800fd0c268850788f14a0c6d0/tensorboard-2.15.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/b6/c8/2f823c8958d5342eafc6dd3e922f0cc4fcf8c2e0460284cc462dae3b60a0/tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/fc/a7/0d4490de967a67f68a538cc9cdb259bff971c4b5787f7765dc7c8f118f71/keras-2.15.0-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/82/41/7fb855444cead5b2213e053447ce3a0b7bf2c3529c443e0cf75b2f13b405/google_auth-2.27.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.27.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth-oauthlib<2,>=0.5 from https://files.pythonhosted.org/packages/71/bf/9e125754d1adb3bc4bd206c4e5df756513b1d23675ac06caa471278d1f3f/google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\denee\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Downloading tensorflow-2.15.0-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl (300.9 MB)\n",
      "   ---------------------------------------- 0.0/300.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/300.9 MB 33.4 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 2.3/300.9 MB 29.7 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 3.7/300.9 MB 29.7 MB/s eta 0:00:11\n",
      "    --------------------------------------- 5.3/300.9 MB 30.8 MB/s eta 0:00:10\n",
      "    --------------------------------------- 7.1/300.9 MB 32.4 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 8.7/300.9 MB 32.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 10.5/300.9 MB 34.4 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 12.6/300.9 MB 36.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 14.5/300.9 MB 38.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 16.7/300.9 MB 40.9 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 18.7/300.9 MB 43.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 21.3/300.9 MB 46.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 23.2/300.9 MB 46.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 25.6/300.9 MB 43.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 27.3/300.9 MB 43.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 29.2/300.9 MB 43.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 32.5/300.9 MB 43.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 35.1/300.9 MB 46.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 37.9/300.9 MB 54.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 40.9/300.9 MB 59.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 43.8/300.9 MB 65.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 46.7/300.9 MB 65.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 49.8/300.9 MB 59.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 52.3/300.9 MB 59.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 55.0/300.9 MB 59.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 57.9/300.9 MB 59.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 60.8/300.9 MB 65.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 64.0/300.9 MB 65.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 66.2/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 69.0/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 71.9/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 74.8/300.9 MB 54.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 77.7/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 80.5/300.9 MB 65.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 83.4/300.9 MB 65.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 86.2/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 89.1/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 91.8/300.9 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 95.0/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 97.4/300.9 MB 54.7 MB/s eta 0:00:04\n",
      "   ------------ -------------------------- 100.2/300.9 MB 65.2 MB/s eta 0:00:04\n",
      "   ------------- ------------------------- 103.0/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------- ------------------------- 105.8/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 108.8/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 111.6/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 114.5/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 117.2/300.9 MB 59.5 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 120.1/300.9 MB 59.8 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 123.1/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------- ---------------------- 125.6/300.9 MB 54.7 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 128.6/300.9 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 131.4/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 134.2/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 137.1/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 140.1/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 142.8/300.9 MB 59.8 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 145.5/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 148.3/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 151.1/300.9 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 154.1/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 156.9/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 159.9/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 162.4/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 165.3/300.9 MB 59.8 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 168.1/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 170.9/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 172.0/300.9 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 174.7/300.9 MB 46.7 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 177.3/300.9 MB 46.7 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 180.1/300.9 MB 54.7 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 183.0/300.9 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 185.9/300.9 MB 59.8 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 189.0/300.9 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 191.3/300.9 MB 65.2 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 194.2/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 197.0/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 199.8/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 202.6/300.9 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 205.5/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 208.4/300.9 MB 59.8 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 211.2/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 214.1/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 216.9/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 219.6/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 222.2/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 225.2/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 227.9/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 230.8/300.9 MB 59.8 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 233.6/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 236.4/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 239.3/300.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 242.1/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 245.0/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 247.9/300.9 MB 65.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 250.8/300.9 MB 54.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 253.3/300.9 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 256.1/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 259.1/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 261.8/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 264.6/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 267.5/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 270.3/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 273.1/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.1/300.9 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 278.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 281.7/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 284.2/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 287.2/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 290.1/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 292.6/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  295.7/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  298.6/300.9 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 300.9/300.9 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB ? eta 0:00:00\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.60.1-cp311-cp311-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 2.9/3.7 MB 91.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 47.3 MB/s eta 0:00:00\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 53.1 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 73.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 5.6/24.4 MB 59.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.4/24.4 MB 59.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.3/24.4 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.1/24.4 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.0/24.4 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.5/24.4 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.6/24.4 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 46.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl (938 kB)\n",
      "   ---------------------------------------- 0.0/938.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 938.7/938.7 kB ? eta 0:00:00\n",
      "Downloading protobuf-4.25.2-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 413.4/413.4 kB 25.2 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.7/5.5 MB 56.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 57.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 50.3 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "   ---------------------------------------- 0.0/442.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 442.0/442.0 kB ? eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "   ---------------------------------------- 0.0/186.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 186.8/186.8 kB ? eta 0:00:00\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.27.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.1 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.25.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68ba946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\denee\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35dc7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the jeopardy JSON file\n",
    "file_path = 'jeopardy.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    jeopardy_questions = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a509f",
   "metadata": {},
   "source": [
    "**First, I will attempt a tensorflow method for classification using a deep learning method (LSTM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8da1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'value' to numerical and categorize as high or low\n",
    "value_threshold = 800  # Define threshold for high/low value\n",
    "for question in jeopardy_questions:\n",
    "    # If 'value' is not a string/integer, set a default value 0\n",
    "    if question['value'] is None or (not isinstance(question['value'], str) and not isinstance(question['value'], int)):\n",
    "        question['value'] = 0\n",
    "    elif isinstance(question['value'], str):\n",
    "        # If 'value' is a string, remove $ and commas and convert to int\n",
    "        question['value'] = int(question['value'].replace('$', '').replace(',', ''))\n",
    "    # If 'value' is an int, no changes\n",
    "    \n",
    "    # Categorize as 'high' or 'low' based on the threshold\n",
    "    question['value_label'] = 'high' if question['value'] > value_threshold else 'low'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aca376",
   "metadata": {},
   "source": [
    "Next, pre-processing the text data(questions) to make them suitable for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06cb4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(jeopardy_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5af3652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and tokenize questions\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['question'])\n",
    "sequences = tokenizer.texts_to_sequences(df['question'])\n",
    "max_sequence_length = max(len(x) for x in sequences)\n",
    "question_padded = pad_sequences(sequences, maxlen=max_sequence_length) #pad the sequence lengths to be equal for the model to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72967260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df['value_label'])\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1383f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data as seen in class\n",
    "X_train, X_val, y_train, y_val = train_test_split(question_padded, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9606a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\denee\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\denee\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model, I opted for a LSTM sequentioal model \n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
    "    LSTM(64),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cf676d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5424/5424 [==============================] - 733s 135ms/step - loss: 0.5702 - accuracy: 0.7245 - val_loss: 0.5784 - val_accuracy: 0.7262\n",
      "Epoch 2/5\n",
      "5424/5424 [==============================] - 725s 134ms/step - loss: 0.4715 - accuracy: 0.7819 - val_loss: 0.6404 - val_accuracy: 0.6922\n",
      "Epoch 3/5\n",
      "5424/5424 [==============================] - 716s 132ms/step - loss: 0.3359 - accuracy: 0.8557 - val_loss: 0.7880 - val_accuracy: 0.6580\n",
      "Epoch 4/5\n",
      "5424/5424 [==============================] - 715s 132ms/step - loss: 0.2203 - accuracy: 0.9094 - val_loss: 1.0188 - val_accuracy: 0.6290\n",
      "Epoch 5/5\n",
      "5424/5424 [==============================] - 722s 133ms/step - loss: 0.1390 - accuracy: 0.9435 - val_loss: 1.3275 - val_accuracy: 0.6397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a790862090>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0f58776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 16s 12ms/step - loss: 1.3275 - accuracy: 0.6397\n",
      "Test Accuracy: 0.6396763920783997\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf759d",
   "metadata": {},
   "source": [
    "**Support Vector Machines (SVM) approach for classifying text data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f516fe8",
   "metadata": {},
   "source": [
    "Next, I will try the classification using SVM on the 'Jeopardy!' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c700350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies not mentioned above\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import gensim.downloader as api\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b69f5da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 11.5% 43.4/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========-----------------------------------------] 18.3% 68.8/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========----------------------------------------] 21.4% 80.4/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============------------------------------------] 29.0% 109.2/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================----------------------------------] 32.5% 122.4/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================------------------------------] 40.1% 150.8/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================-----------------------------] 43.7% 164.2/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================-------------------------] 51.2% 192.4/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================-----------------------] 54.9% 206.5/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================-------------------] 62.6% 235.3/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================-----------------] 66.3% 249.2/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 73.7% 277.1/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================------------] 77.3% 290.6/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================================--------] 84.6% 318.1/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================------] 88.6% 333.3/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================================---] 94.2% 354.3/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 99.5% 374.1/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load GloVe model from gensim\n",
    "glove_model = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9817968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create an average embedding for a text\n",
    "def document_vector(word_list):\n",
    "    # Assume word_list is already a list of words, directly use them\n",
    "    embeddings = [glove_model[word] for word in word_list if word in glove_model]\n",
    "    if not embeddings:\n",
    "        return np.zeros(300)  # Return a zero vector if embeddings list is empty\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b07835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'jeopardy.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    jeopardy_questions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "049f7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'value' to numerical and categorize as high or low\n",
    "value_threshold = 800  # Define threshold for high/low value\n",
    "for question in jeopardy_questions:\n",
    "    if question['value'] is None or (not isinstance(question['value'], str) and not isinstance(question['value'], int)):\n",
    "        question['value'] = 0\n",
    "    elif isinstance(question['value'], str):\n",
    "        question['value'] = int(question['value'].replace('$', '').replace(',', ''))\n",
    "    question['value_label'] = 'high' if question['value'] > value_threshold else 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "477d73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(jeopardy_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4db60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the questions to split them into words\n",
    "df['processed_questions'] = df['question'].apply(lambda x: x.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "060593ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text data using the document_vector function\n",
    "df['question_vector'] = df['processed_questions'].apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa370ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test Split\n",
    "X = np.array(list(df['question_vector']))  # Convert to array\n",
    "y = df['value_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e3ee66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train SVM\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae52a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7189415940626008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denee\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denee\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00     12194\n",
      "         low       0.72      1.00      0.84     31192\n",
      "\n",
      "    accuracy                           0.72     43386\n",
      "   macro avg       0.36      0.50      0.42     43386\n",
      "weighted avg       0.52      0.72      0.60     43386\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denee\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c014d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3bb980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
